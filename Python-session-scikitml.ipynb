{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Sample `scikit-multilearn` work session"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import skmultilearn.cluster as cluster\n",
    "from skmultilearn.dataset import available_data_sets\n",
    "from skmultilearn.dataset import load_dataset\n",
    "from skmultilearn.problem_transform import BinaryRelevance\n",
    "from skmultilearn.adapt import MLkNN\n",
    "from sklearn.svm import SVC\n",
    "import sklearn.metrics as metrics"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## See the available datasets in the scikit-multilearn repository"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "('bibtex', 'undivided')\n",
      "('bibtex', 'test')\n",
      "('bibtex', 'train')\n",
      "('birds', 'undivided')\n",
      "('birds', 'test')\n",
      "('birds', 'train')\n",
      "('Corel5k', 'undivided')\n",
      "('Corel5k', 'test')\n",
      "('Corel5k', 'train')\n",
      "('delicious', 'undivided')\n",
      "('delicious', 'test')\n",
      "('delicious', 'train')\n",
      "('emotions', 'undivided')\n",
      "('emotions', 'test')\n",
      "('emotions', 'train')\n",
      "('enron', 'undivided')\n",
      "('enron', 'test')\n",
      "('enron', 'train')\n",
      "('genbase', 'undivided')\n",
      "('genbase', 'test')\n",
      "('genbase', 'train')\n",
      "('mediamill', 'undivided')\n",
      "('mediamill', 'test')\n",
      "('mediamill', 'train')\n",
      "('medical', 'undivided')\n",
      "('medical', 'test')\n",
      "('medical', 'train')\n",
      "('rcv1subset1', 'undivided')\n",
      "('rcv1subset1', 'test')\n",
      "('rcv1subset1', 'train')\n",
      "('rcv1subset2', 'undivided')\n",
      "('rcv1subset2', 'test')\n",
      "('rcv1subset2', 'train')\n",
      "('rcv1subset3', 'undivided')\n",
      "('rcv1subset3', 'test')\n",
      "('rcv1subset3', 'train')\n",
      "('rcv1subset4', 'undivided')\n",
      "('rcv1subset4', 'test')\n",
      "('rcv1subset4', 'train')\n",
      "('rcv1subset5', 'undivided')\n",
      "('rcv1subset5', 'test')\n",
      "('rcv1subset5', 'train')\n",
      "('scene', 'undivided')\n",
      "('scene', 'test')\n",
      "('scene', 'train')\n",
      "('tmc2007_500', 'undivided')\n",
      "('tmc2007_500', 'test')\n",
      "('tmc2007_500', 'train')\n",
      "('yeast', 'undivided')\n",
      "('yeast', 'test')\n",
      "('yeast', 'train')\n"
     ]
    }
   ],
   "source": [
    "for x in available_data_sets().keys():\n",
    "    print(x)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load and explore a dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "emotions:undivided - exists, not redownloading\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[('amazed-suprised', ['0', '1']),\n",
       " ('happy-pleased', ['0', '1']),\n",
       " ('relaxing-calm', ['0', '1']),\n",
       " ('quiet-still', ['0', '1']),\n",
       " ('sad-lonely', ['0', '1']),\n",
       " ('angry-aggresive', ['0', '1'])]"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "emotions_X, emotions_Y, attributes, labels = load_dataset('emotions', 'undivided')\n",
    "labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{(1, 2): 91.0, (0, 5): 92.0, (1, 5): 12.0, (0, 1): 56.0, (2, 3): 104.0, (2, 4): 95.0, (3, 4): 105.0, (4, 5): 20.0, (2, 5): 7.0, (0, 4): 10.0, (1, 4): 1.0, (0, 2): 13.0, (1, 3): 7.0, (3, 5): 2.0}\n"
     ]
    }
   ],
   "source": [
    "concurrence_builder = cluster.LabelCooccurrenceGraphBuilder(weighted=True, include_self_edges=False)\n",
    "concurrence = concurrence_builder.transform(emotions_Y)\n",
    "print(concurrence)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load train and test partitions to fit two classifiers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "emotions:train - exists, not redownloading\n",
      "emotions:test - exists, not redownloading\n"
     ]
    }
   ],
   "source": [
    "emotions_X_train, emotions_Y_train, _, _ = load_dataset('emotions', 'train')\n",
    "emotions_X_test,  emotions_Y_test, _, _  = load_dataset('emotions', 'test')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "BinaryRelevance(classifier=SVC(C=1.0, cache_size=200, class_weight=None, coef0=0.0,\n",
       "  decision_function_shape='ovr', degree=3, gamma='auto', kernel='rbf',\n",
       "  max_iter=-1, probability=False, random_state=None, shrinking=True,\n",
       "  tol=0.001, verbose=False),\n",
       "        require_dense=[True, True])"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "class1 = BinaryRelevance(classifier=SVC(gamma=\"auto\"))\n",
    "class1.fit(emotions_X_train, emotions_Y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "MLkNN(ignore_first_neighbours=0, k=10, s=1.0)"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "class2 = MLkNN()\n",
    "class2.fit(emotions_X_train, emotions_Y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Hamming loss:  0.26485148514851486\n",
      "Accuracy:  0.14356435643564355\n"
     ]
    }
   ],
   "source": [
    "prediction = class1.predict(emotions_X_test)\n",
    "print('Hamming loss: ', metrics.hamming_loss(emotions_Y_test, prediction))\n",
    "print('Accuracy: ', metrics.accuracy_score(emotions_Y_test, prediction))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Hamming loss:  0.30363036303630364\n",
      "Accuracy:  0.13366336633663367\n"
     ]
    }
   ],
   "source": [
    "prediction = class2.predict(emotions_X_test)\n",
    "print('Hamming loss: ', metrics.hamming_loss(emotions_Y_test, prediction))\n",
    "print('Accuracy: ', metrics.accuracy_score(emotions_Y_test, prediction))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
