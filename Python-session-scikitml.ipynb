{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Sample `scikit-multilearn` work session"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [],
   "source": [
    "import skmultilearn.cluster as cluster\n",
    "from skmultilearn.dataset import available_data_sets\n",
    "from skmultilearn.dataset import load_dataset\n",
    "from skmultilearn.problem_transform import BinaryRelevance\n",
    "from skmultilearn.adapt import MLkNN\n",
    "from sklearn.svm import SVC\n",
    "import sklearn.metrics as metrics\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## See the available datasets in the scikit-multilearn repository"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "('bibtex', 'undivided')\n",
      "('bibtex', 'test')\n",
      "('bibtex', 'train')\n",
      "('birds', 'undivided')\n",
      "('birds', 'test')\n",
      "('birds', 'train')\n",
      "('Corel5k', 'undivided')\n",
      "('Corel5k', 'test')\n",
      "('Corel5k', 'train')\n",
      "('delicious', 'undivided')\n",
      "('delicious', 'test')\n",
      "('delicious', 'train')\n",
      "('emotions', 'undivided')\n",
      "('emotions', 'test')\n",
      "('emotions', 'train')\n",
      "('enron', 'undivided')\n",
      "('enron', 'test')\n",
      "('enron', 'train')\n",
      "('genbase', 'undivided')\n",
      "('genbase', 'test')\n",
      "('genbase', 'train')\n",
      "('mediamill', 'undivided')\n",
      "('mediamill', 'test')\n",
      "('mediamill', 'train')\n",
      "('medical', 'undivided')\n",
      "('medical', 'test')\n",
      "('medical', 'train')\n",
      "('rcv1subset1', 'undivided')\n",
      "('rcv1subset1', 'test')\n",
      "('rcv1subset1', 'train')\n",
      "('rcv1subset2', 'undivided')\n",
      "('rcv1subset2', 'test')\n",
      "('rcv1subset2', 'train')\n",
      "('rcv1subset3', 'undivided')\n",
      "('rcv1subset3', 'test')\n",
      "('rcv1subset3', 'train')\n",
      "('rcv1subset4', 'undivided')\n",
      "('rcv1subset4', 'test')\n",
      "('rcv1subset4', 'train')\n",
      "('rcv1subset5', 'undivided')\n",
      "('rcv1subset5', 'test')\n",
      "('rcv1subset5', 'train')\n",
      "('scene', 'undivided')\n",
      "('scene', 'test')\n",
      "('scene', 'train')\n",
      "('tmc2007_500', 'undivided')\n",
      "('tmc2007_500', 'test')\n",
      "('tmc2007_500', 'train')\n",
      "('yeast', 'undivided')\n",
      "('yeast', 'test')\n",
      "('yeast', 'train')\n"
     ]
    }
   ],
   "source": [
    "for x in available_data_sets().keys():\n",
    "    print(x)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load and explore a dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "emotions:undivided - exists, not redownloading\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[('amazed-suprised', ['0', '1']),\n",
       " ('happy-pleased', ['0', '1']),\n",
       " ('relaxing-calm', ['0', '1']),\n",
       " ('quiet-still', ['0', '1']),\n",
       " ('sad-lonely', ['0', '1']),\n",
       " ('angry-aggresive', ['0', '1'])]"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "emotions_X, emotions_Y, attributes, labels = load_dataset('emotions', 'undivided')\n",
    "labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Label frequencies:  [[173 166 264 148 168 189]]\n",
      "MeanIR:  1.4780684597524212\n"
     ]
    }
   ],
   "source": [
    "labelfreqs = emotions_Y.sum(axis=0)\n",
    "print(\"Label frequencies: \", labelfreqs)\n",
    "print(\"MeanIR: \", np.mean(labelfreqs.max() / labelfreqs))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Card:  1.8684654300168635\n",
      "Dens:  0.3114109050028106\n"
     ]
    }
   ],
   "source": [
    "print(\"Card: \", emotions_Y.sum() / emotions_Y.shape[0])\n",
    "print(\"Dens: \", emotions_Y.sum() / emotions_Y.shape[0] / emotions_Y.shape[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{(1, 2): 91.0, (0, 5): 92.0, (1, 5): 12.0, (0, 1): 56.0, (2, 3): 104.0, (2, 4): 95.0, (3, 4): 105.0, (4, 5): 20.0, (2, 5): 7.0, (0, 4): 10.0, (1, 4): 1.0, (0, 2): 13.0, (1, 3): 7.0, (3, 5): 2.0}\n"
     ]
    }
   ],
   "source": [
    "concurrence_builder = cluster.LabelCooccurrenceGraphBuilder(weighted=True, include_self_edges=False)\n",
    "concurrence = concurrence_builder.transform(emotions_Y)\n",
    "print(concurrence)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load train and test partitions to fit two classifiers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "emotions:train - exists, not redownloading\n",
      "emotions:test - exists, not redownloading\n"
     ]
    }
   ],
   "source": [
    "emotions_X_train, emotions_Y_train, _, _ = load_dataset('emotions', 'train')\n",
    "emotions_X_test,  emotions_Y_test, _, _  = load_dataset('emotions', 'test')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "BinaryRelevance(classifier=SVC(C=1.0, cache_size=200, class_weight=None, coef0=0.0,\n",
       "  decision_function_shape='ovr', degree=3, gamma='auto', kernel='rbf',\n",
       "  max_iter=-1, probability=False, random_state=None, shrinking=True,\n",
       "  tol=0.001, verbose=False),\n",
       "        require_dense=[True, True])"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "class1 = BinaryRelevance(classifier=SVC(gamma=\"auto\"))\n",
    "class1.fit(emotions_X_train, emotions_Y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "MLkNN(ignore_first_neighbours=0, k=10, s=1.0)"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "class2 = MLkNN()\n",
    "class2.fit(emotions_X_train, emotions_Y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Hamming loss:  0.26485148514851486\n",
      "Accuracy:  0.14356435643564355\n"
     ]
    }
   ],
   "source": [
    "prediction = class1.predict(emotions_X_test)\n",
    "print('Hamming loss: ', metrics.hamming_loss(emotions_Y_test, prediction))\n",
    "print('Accuracy: ', metrics.accuracy_score(emotions_Y_test, prediction))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Hamming loss:  0.30363036303630364\n",
      "Accuracy:  0.13366336633663367\n"
     ]
    }
   ],
   "source": [
    "prediction = class2.predict(emotions_X_test)\n",
    "print('Hamming loss: ', metrics.hamming_loss(emotions_Y_test, prediction))\n",
    "print('Accuracy: ', metrics.accuracy_score(emotions_Y_test, prediction))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.51      0.43      0.46        54\n",
      "          1       0.24      0.17      0.20        59\n",
      "          2       0.69      0.84      0.76        96\n",
      "          3       0.59      0.37      0.46        59\n",
      "          4       0.37      0.18      0.24        73\n",
      "          5       0.66      0.33      0.44        58\n",
      "\n",
      "avg / total       0.52      0.42      0.45       399\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(metrics.classification_report(emotions_Y_test, prediction))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
